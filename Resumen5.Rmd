---
title: "Resumen5"
author: "Valentina Paz Campos Olguín"
date: "2023-09-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Inferencia no paramétrica con proporciones

Aquí se emplearán pruebas para inferir acerca de proporciones cuyas hipótesis nula y alternativa **no** mencionan parámetro alguno. Aún mejor, ninguna de las pruebas hace alguna suposición sobre la distribución de la población desde donde viene la muestra analizada.

Son menos restrictivas, pero tienen dos grandes desventajas:

-   Entregan menos información, ya que las hipótesis se basan en entregar una igualdad o desigualdad pero no indica cuáles serían las proporciones.

-   Cuándo están las condiciones para emplear una prueba parámetrica, las pruebas no paramétricas tienen menor poder estadístico, por lo que se necesita aumentar el tamaño de las muestras.

### Prueba Chi-cuadrado de Pearson

Sirve para inferir con proporciones cuando disponemos de dos variables categóricas y una de ellas es dicotómica (tiene solo 2 niveles).

Condiciones:

1.  Las observaciones deben ser independientes entre sí.
2.  Debe haber a lo menos 5 observaciones esperadas en cada grupo.

#### Prueba Chi-cuadrado de homogeneidad

Resulta adecuada si queremos determinar si dos poblaciones (la variable dicotómica) presentan las mismas proporciones en los diferentes niveles de una variable categórica.

Se necesita determinar si las diferencias entre las cantidades observadas y las esperadas son muy grandes como para evidenciar de que las preferencias son disímiles.

Cantidad de observaciones esperadas para cada grupo:

-   $n_{i}$: total de observaciones en la fila i

-   $n_{j}$: total de observaciones en la columna j

-   $n$: tamaño de la muestra

$$
E_{ij} = \frac{n_{i}n_{j}}{n}
$$

Se puede utilizar Z para realizar una prueba adecuada.

$$
Z = \frac{estimadorpuntual - valornulo}{SE_{estimadorpuntual}}
$$

Podríamos usar esta fórmula de la diferencia estandarizada para cada uno de los grupos, donde:

-   El estimador puntual corresponde a la frecuencia observada para el grupo.

-   El valor nulo corresponde a la frecuencia esperada para el grupo.

-   El error estándar del estimador puntual es la raíz cuadrada del valor nulo.

Estadístico de prueba $\chi²$

$$
\chi² = \sum_{i=1}^{m}\sum_{j=1}^{n}\frac{(cantidadObservada - cantidadEsperada)²}{cantidadEsperada}
$$

El estadístico $\chi²$ sigue una distribución chi-cuadrado con $v = (m+1)(n-1)$ grados de libertad.

El valor p está dado por el área bajo la curva de la distribución chi-cuadrado con valores mayores al obtenido para el estadístico de prueba.

```{r}
#Crear tabla de contingencia
programadores <- c(42, 56, 51, 27, 24)
programadoras <- c(25, 24, 27, 15, 9)

tabla <- as.table(rbind(programadores, programadoras))

dimnames(tabla) <- list(sexo = c("programadores", "programadoras"),
                        lenguajes = c("C", "Java", "Python", "Ruby", "Otro"))

print(tabla)

#Hacer prueba chi-cuadrado de homogeneidad
prueba <- chisq.test(tabla)
print(prueba)
```

#### Prueba chi-cuadrado de bondad de ajuste

Permite comprobar si una distribución de frecuencias observada se asemeja a una distribución esperada. Usualmente se emplea para comprobar si una muestra es representativa de la población.

Se debe sacar la proporción del grupo seleccionado de la población y el total, para luego multiplicarlo por el tamaño del grupo seleccionado de la muestra.

Luego, si para cada grupo se esperan más de 5 observaciones, se verifica la segunda condición.

```{r}
#Crear tabla de contingencia
nomina <- c(236, 78, 204, 76, 66)
muestra <- c(17, 9, 14, 10, 5)

tabla <- as.table(rbind(nomina, muestra))

dimnames(tabla) <- list(grupo = c("Nómina", "Muestra"),
                        lenguajes = c("C", "Java", "Python", "Ruby", "Otro"))

print(tabla)

#Verificar si se esperan más de 5 observaciones por cada grupo
n_nomina <- sum(nomina)
n_muestra <- sum(muestra)
proporciones <- round(nomina/n_nomina, 3)
esperados <- round(proporciones * n_muestra, 3)
print(esperados)

#Hacer prueba chi-cuadrado de homogeneidad
prueba <- chisq.test(tabla, correct = FALSE)
print(prueba)

#En este caso p = 0,461, por lo que se falla al rechazar la hipótesis nula con un nivel de significación de 0.05. Podemos concluir con un 95% de confianza que no hay evidencia de que la muestra seleccionada no sea representativa de la nómina de programadores de la empresa.
```

#### Prueba chi-cuadrado de independencia

Permite determinar si dos variables categóricas, de una misma población, son estadísticamente independientes o si, por el contrario, están relacionadas.

Se calcula la frecuencia esperada para cada celda y se analiza si se cumplen las condiciones.

```{r}
#Crear tabla de contingencia
comestible <- c(404, 1948, 32, 228, 1596)
venenoso <- c(48, 1708, 0, 600, 1556)

tabla <- as.table(rbind(comestible, venenoso))

dimnames(tabla) <- list(tipo = c("comestible", "venenoso"),
                        sombrero = c("campana", "convexo", "hundido", "nudoso", "plano"))

print(tabla)

#Hacer prueba chi-cuadrado de independencia
prueba <- chisq.test(tabla)
cat("\nLa prueba internamente calcula los valores esperados:\n")
esperados <- round(prueba[["expected"]], 3)
print(esperados)

cat("\nResultado de la prueba:\n")
print(prueba)
```

### Pruebas para muestras pequeñas

#### Prueba exacta de Fisher

Es una alternativa a la prueba $\chi^2$ de independencia en el caso de que **ambas variables** sean **dicotómicas.** Así, las hipótesis a contrastar son:

$H_{0}$: Las variables son independientes

$H_{A}$: Las variables están relacionadas

La probabilidad exacta de observar el conjunto de frecuencias de la tabla está dada por la siguiente ecuación:

$$
p = \frac{(a+b)!(c+d)!(a+c)!(b+d)!}{n!a!b!c!d!}
$$

Suma de las probabilidades de todas las tablas con probabilidad menor o igual que la tabla dada.

```{r}
#Construir la tabla de contingencia
#Primer parámetro: Cantidad total de Argh
#Segundo parámetro: Cantidad total de Grrr
vacuna <- c(rep("Argh", 6), rep("Grrr", 11))
#Primer parámetro: Cantidad total de humanos
#Segundo parámetro: Cantidad total de vampiros
resultado <- c(rep("Humano", 12), rep("Vampiro", 5))
datos <- data.frame(resultado, vacuna)
tabla <- xtabs(~., datos)
print(tabla)

#Aplicar prueba exacta de Fisher
alfa <- 0.05
prueba <- fisher.test(tabla, 1-alfa)
print(prueba)

#Al calcular cada probabilidad (cambiando los valores de los infectados y sanos), se obtienen:
#a: 0.001
#b: 0.320
#c: 0.027
#d: 0.400
#e: 0.178

#p = 0.075 + 0.001 + 0.027 = 0.103
#Se concluye con un 95% de confianza que no existe evidencia de que exista una asociación entre la cantidad de nuevos vampiros y la vacuna recibida.
```

#### Prueba de mcNemar

Resulta apropiada cuando una misma característica, con respuesta dicotómica, se mide en dos ocasiones diferentes para los mismos sujetos (muestras pareadas) y queremos determinar si se produce o no un cambio significativo entre ambas mediciones.

Las celdas a y d corresponden a las instancias en que no hay cambios. La celda b representa a las instancias que cambian de Presente a Ausente, y la celda c a instancias que cambian de Ausente a Presente.

Hipótesis para la prueba de mcNemar:

-   $H_{0}$: **No** hay cambios significativos en las respuestas

-   $H_{A}$: **Sí** hay cambios significativos en las respuestas

Cantidad de instancias en que se producen cambios: $b+c$

Se espera que $(b+c)/2$ cambien en un sentido y la otra mitad cambie al otro sentido.

$$
\chi² = \frac{(b-c)²}{b+c}
$$

Estadístico de prueba con la corrección de Yates

$$
\chi² = \frac{(|b-c| -1)²}{b+c}
$$

El valor p está dado por el área bajo la cola superior de la distribución chi-cuadrado.

```{r}
#Construir la tabla de contingencia
alumno <- seq(1:25)
# Modelo 1: Antes de prueba
# Primer parámetro: Cantidad total de correctos
# Segundo parámetro: Cantidad total de incorrectos
modelo_1 <- c(rep("Correcto", 16), rep("Incorrecto", 9))

# Modelo 2: Después de prueba
# Primer parámetro: Cantidad de correctos-correctos
# Segundo parámetro: Cantidad total de incorrectos
# Tercer parámetro: Cantidad de incorrectos-correctos
modelo_2 <- c(rep("Correcto", 9), rep("Incorrecto", 11), rep("Correcto", 5))

#             Correcto  Incorrecto  Total
# Correcto       9          5
# Incorrecto                         11
# Total          16         9

datos <- data.frame(alumno, modelo_2, modelo_1)
tabla <- table(modelo_2, modelo_1)
print(tabla)

#Aplicar prueba de McNemar
prueba <- mcnemar.test(tabla)
print(prueba)

#Como o = 0.774, se falla al rechazar la hipótesis nula y se concluye que no hay evidencia suficiente para creer que existe una diferencia en el desempeño de ambos calificadores.
```

### Prueba Q de Cochran

Es una extensión de la prueba de mcNemar, adecuada cuando la variable de respuesta es dicotómica y la variable independiente tiene más de dos observaciones pareadas (cuando ambas variables son dicotómicas, esta prueba es equivalente a la de mcNemar).

Hipótesis contrastadas por la prueba Q de Cochran

-   $H_{0}$: La proporción de "éxitos" es la misma para todos los grupos

-   $H_{A}$: La proporción de "éxitos" es distinta para al menos un grupo

Condiciones

1.  La variable de respuesta es dicotómica
2.  La variable independiente es categórica
3.  Las observaciones son independientes entre sí
4.  El tamaño de la muestra es lo suficientemente grande. Se sugiere que n\*k \>= 24, donde n es el número de casos cuyas respuestas no son únicamente éxitos o fracasos y k es la cantidad de niveles en la variable independiente.

-   $N$: Cantidad de casos (sujetos, elementos o bloques)

-   $k$: Cantidad de mediciones (niveles de la variable independiente)

-   $x_{ij}$: Observación registrada para el caso $i$ y en la oportunidad $j$

$$
Q = \frac{(k-1)|kC-T²|}{kT-R}
$$

$$
C = \sum_{j=1}^{k}(\sum_{i=1}^{N}x_{ij})²
$$

$$
T = \sum_{i=1}^{N}(\sum_{i=1}^{k}x_{ij})
$$

$$
R = \sum_{i=1}^{N}(\sum_{j=1}^{k}x_{ij})²
$$

La hipótesis nula de la prueba ! de Cochran no es específica, sino que comprueba la igualdad de todas las proporciones. Esta clase de hipótesis nula suele llamarse ómnibus.

Existen pruebas que permiten saber qué grupos presentan diferencias, y son llamadas *post-hoc* o *a posteriori.*

Solo se hará el procedimiento post-hoc si la prueba ómnibus rechaza la hipótesis nula en favor de la hipótesis alternativa.

Cuando constrastamos hipótesis acotamos la probabilidad de cometer errores tipo I por medio del nivel de significación $\alpha$. Sin embargo, cuando hacemos múltiples contrastes de hipótesis simultáneamente, cada uno de ellos tendrá una probabilidad $\alpha$ de cometer un error de tipo I. Esto se traduce en un incremento de la probabilidad de cometer este tipo de errores a medida que aumenta la cantidad de hipótesis contrastadas.

La corrección de Bonferroni es el método más sencillo para ajustar los valores de p, pero no se recomienda su uso si el número de grupos es alto, ya que es muy convervador (mantiene la probabilidad de cometer un error tipo I más baja que el nivel de significación establecido, por lo que es más propensa a cometer errores tipo II).

La corrección de Holm tiene mayor poder estadístico que la de Bonferroni. Comienza por efectuar las pruebas entre pares de bloques y luego ordena los valores p en forma creciente.

Factor de Holm:

-   $\alpha$: nivel de significación

-   $N$: cantidad de comparaciones efectuadas

-   $i$: importancia de la comparación (posición en la lista de valores p ordenados)

$$
HB_{i} = \frac{\alpha}{N-i+1}
$$

Luego, se compara el valor p con su respectivo factor de Holm y, si el valor p es menor, se considera que existe una diferencia significativa.

```{r}
library(rcompanion)
library(dplyr)
library(tidyr)
library(tidyverse)
library(RVAideMemoire)

#Crear matriz de datos
# Instancia  Annealing  Col. hormigas  Alg. genético
# 1             0             0             1
# 2             1             0             0
# 3             0             1             1

instancia <- 1:15
annealing <- c(0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0)
hormigas <- c(0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1)
genetico <- c(1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1)
datos <- data.frame(instancia, annealing, hormigas, genetico)

#Llevar matriz de datos a formato largo
datos <- datos %>% pivot_longer(c("annealing", "hormigas", "genetico"),
                                names_to = "metaheuristica",
                                values_to = "resultado")

datos[["instancia"]] <- factor(datos[["instancia"]])
datos[["metaheuristica"]] <- factor(datos[["metaheuristica"]])

#Hacer prueba Q de Cochran
prueba <- cochran.qtest(resultado ~ metaheuristica | instancia, data = datos, alpha = 0.05)
print(prueba)

#Se rechaza la hipótesis nula en favor de la hipótesis alternativa. Elsa concluye con 95% de confianza que al menos una de las metaheurísticas tiene un desempeño diferente a las demás.

#Procedimiento post-hoc con corrección de Bonferroni
post_hoc_1 <- pairwiseMcnemar(resultado ~ metaheuristica | instancia, data = datos, method = "bonferroni")

cat("\nProcedimiento post-hoc con corrección de Bonferroni\n")
print(post_hoc_1)

#Procedimiento post-hoc con corrección de Holm
post_hoc_2 <- pairwiseMcnemar(resultado ~ metaheuristica | instancia, data = datos, method = "holm")

cat("\nProcedimiento post-hoc con corrección de Holm\n")
print(post_hoc_2)

#La evidencia no es lo suficientemente fuerte para poder afirmar que existen diferencias entre las metaheurísticas, pero que podría ser adecuado hacer un estudio con una muestra mayor puesto que los resultados de la prueba Q de Cochran y de los procedimientos post-hoc son contradictorios.
```

La prueba de chi-cuadrado ha sido empleada en este estudio pediátrico, que busca encontrar una relación entre los tipos de consultas (accidentes y no accidentes) y las estaciones del año (como lo es invierno y verano en este caso).

Se tiene que la hipótesis nula es que las variables son independientes, mientras que la hipótesis alternativa es que las variables tienen relación.

En la tabla presentada, se tiene que el valor de \$\\chi²\$ es igual a 512,5. Luego de calcular este valor, se evalúa si el estadístico es significativo. Tomando como grado de libertad = 1, se tiene que p \< 0.005. Por lo tanto, se rechaza la hipótesis nula en favor de la hipótesis alternativa, es decir, que existe una relación entre las variables.
