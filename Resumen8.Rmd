---
title: "Resumen8"
author: "Valentina Paz Campos Olguín"
date: "2023-10-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Métodos clásicos para enfrentar datos problemáticos

### Transformación de datos

La primera forma de enfrentar a los datos problemáticos es transformarlos a una escala diferente donde cumpla las condiciones.

#### Transformación lineal

Se aplica la función lineal, donde m y n son constantes.

$$
y_i = mx_i + n
$$

#### Transformación logarítmica

Puede servir cuando existen distribuciones muy asimétricas, pues ayuda a reducir la desviación y facilita el cumplimiento de la condición de normalidad requerida.

Por ejemplo, luego de transformar las variables, se evidencia una fuerte relación entre el peso corporal y el peso del cerebro de los animales.

```{r}
# Load required library
library(ggpubr)

# Load data
animal <- c(
  "Mountain beaver", "Cow", "Grey wolf", "Goat", "Guinea pig", 
  "Diplodocus", "Asian elephant", "Donkey", "Horse", 
  "Potar monkey", "Cat", "Giraffe", "Gorilla", "Human", 
  "African elephant", "Triceratops", "Rhesus monkey", "Kangaroo", 
  "Golden hamster", "Mouse", "Rabbit", "Sheep", "Jaguar", 
  "Chimpanzee", "Brachiosaurus", "Mole", "Pig"
)

body_weight <- c(
  1.35, 465, 36.33, 27.66, 1.04, 11700, 2547, 187.1, 521, 10, 
  3.3, 529, 207, 62, 6654, 9400, 6.8, 35, 0.12, 0.023, 2.5
)

# Cargar datos
brain_weight <- c(465, 423, 119.5, 115, 5.5, 50, 4603, 419, 655, 115, 25.6, 
                  680, 406, 1320, 5712, 70, 179, 56, 1, 0.4, 12.1, 175, 157, 
                  440, 154.5, 3, 180)

datos <- data.frame(animal, body_weight, brain_weight)

# Aplicar transformación logarítmica
log_cuerpo <- log(body_weight)
log_cerebro <- log(brain_weight)
datos <- data.frame(datos, log_cuerpo, log_cerebro)

# Histogramas para el peso cerebral antes y después de la transformación logarítmica
g3 <- ggihistogram(datos, x = "brain_weight", bins = 10,
                   xlab = "Peso del cerebro [g]", ylab = "Frecuencia", 
                   color = "red", fill = "red")

g4 <- ggihistogram(datos, x = "log_cerebro", bins = 10,
                   xlab = "Peso del cerebro [log(g)]", ylab = "Frecuencia",
                   color = "red", fill = "red")

# Crear una única figura con ambos histogramas
histograma <- ggarrange(g3, g4, ncol = 2, nrow = 1)
titulo <- text_grob("Efecto de la transformación logarítmica", face = "bold", size = 14)
histograma <- annotate_figure(histograma, top = titulo)
print(histograma)

# Gráficos de dispersión para la relación entre peso corporal y peso del cerebro, 
# antes y después de aplicar la transformación logarítmica
g1 <- ggscatter(datos, x = "body_weight", y = "brain_weight", 
                color = "red", xlab = "Peso corporal [kg]", 
                ylab = "Peso del cerebro [g]") + rotate_x_text(45)

g2 <- ggscatter(datos, x = "log_cuerpo", y = "log_cerebro",
                color = "red", xlab = "Peso corporal [log(kg)]",
                ylab = "Peso del cerebro [log(g)]") + rotate_x_text(45)

# Crear una única figura con los gráficos de dispersión
dispersion <- ggarrange(g1, g2, ncol = 2, nrow = 1)
texto <- "Relación entre el peso corporal y el peso del cerebro"
titulo <- text_grob(texto, face = "bold", size = 14)
dispersion <- annotate_figure(dispersion, top = titulo)
print(dispersion)

```

Cuando se comparan medias de datos tras una transformación logarítmica se están comparando realmente medias geométricas.

Fórmula de media geométrica

Si dos variables a las que se ha aplicado la transformación logarítmica tienen igual media, entonces las medias geométricas de las variables originales son iguales.

#### Escalera de potencias de Tukey

Ayuda a cambiar la forma de una distribución asimétrica para que se asemeje a la normal.

$$
y = x^{\lambda}
$$

Si $\lambda = 1$, no se hace transformación.

Si $\lambda = 0$, se hace transformación logarítmica.

$$
\bar{x}_{\lambda} = x^{\lambda}, \lambda > 0
$$

$$
\bar{x}_{\lambda} = log(x), \lambda = 0
$$

$$
\bar{x}_{\lambda} = -(x^{\lambda}), \lambda < 0
$$

A medida que $\lambda$ aumenta, se reduce la asimetría negativa.

Si bien se tiene la certeza de que se pueden encontrar diferencias significativas en la variable transformada, estas diferencias también existen en la variable original. Los estadísticos e intervalos de confianza **NO** son los mismos que arrojarían las pruebas con los datos originales.

transformTukey(x, start, end, int, plotit, verbose, quiet, statistic, returnLambda):

-   x: vector de valores a transformar

-   start: valor inicial de $\lambda$ a evaluar

-   end: valor final de $\lambda$ a evaluar

-   int: intervalo de los valores de $\lambda$ a evaluar

-   plotit: si toma valor TRUE, entrega los siguientes gráficos:

    -   Estadístico de la prueba de normalidad versus $\lambda$

    -   Histograma de los valores transformados

    -   Gráfico Q-Q de los valores transformados

-   verbose: si es TRUE, muestra información adicional sobre la prueba de normalidad con respecto a $\lambda$

-   quiet: si es TRUE, no muestra información alguna por pantalla

-   statistic: si es 1, usa la prueba de normalidad Shapiro-Wilk. Con valor 2, usa la prueba de Anderson-Darling.

-   returnLambda: si es TRUE, devuelve el valor de $\lambda$. Si es FALSE, devuelve los datos transformados.

```{r}
# Cargar bibliotecas
library(ggpubr)
library(rcompanion)

# Cargar datos
Year <- c(1610, 1620, 1630, 1640, 1650, 1660, 1670, 1680, 1690, 1700, 1710,
          1720, 1730, 1740, 1750, 1760, 1770, 1780, 1790, 1800, 1810, 1820,
          1830, 1840, 1850)
Population <- c(0.00035, 0.002302, 0.004646, 0.026634, 0.050368, 0.075058, 
               0.111935, 0.151507, 0.210372, 0.250888, 0.331711, 0.466185, 
               0.629445, 0.905563, 1.17076, 1.593625, 2.148076, 2.780369,
               3.922914, 5.308483, 7.239881, 9.638453, 12.86602, 17.069453, 
               23.191876)

datos <- data.frame(Year, Population)

# Gráfico de dispersión e histograma
g1 <- ggihistogram(datos, x = "Population", bins = 10,
                   xlab = "Población (millones)", ylab = "Frecuencia",
                   color = "blue", fill = "blue")

g2 <- ggscatter(datos, x = "Year", y = "Population", color = "blue",
                xlab = "Año", ylab = "Población (millones)")

# Histograma de la población y población por año
original <- ggarrange(g1, g2, ncol = 2, nrow = 1)
texto <- "Histograma de la población y población por año"
titulo <- text_grob(texto, face = "bold", size = 14)
original <- annotate_figure(original, top = titulo)
print(original)

# Transformaciones de la población
lambda_menos_dos <- -1 / (datos$Population ** 2)
lambda_menos_uno <- -1 / datos$Population
lambda_menos_un_medio <- -1 / sqrt(datos$Population)
lambda_cero <- log(datos$Population)
lambda_un_medio <- sqrt(datos$Population)
lambda_dos <- datos$Population ** 2

transformaciones <- data.frame(datos, lambda_menos_dos, lambda_menos_uno, 
                              lambda_menos_un_medio, lambda_cero, 
                              lambda_un_medio, lambda_dos)

# Gráficos de dispersión para la transformación de Tukey de la población y el año,
# usando distintos valores de lambda
g1 <- ggscatter(transformaciones, x = "Year", y = "lambda_menos_dos",
                color = "blue", xlab = "Año", 
                ylab = "lambda = -2") + rotate_x_text(45)

g2 <- ggscatter(transformaciones, x = "Year", y = "lambda_menos_uno",
                color = "blue", xlab = "Año", 
                ylab = "lambda = -1") + rotate_x_text(45)

g3 <- ggscatter(transformaciones, x = "Year", y = "lambda_menos_un_medio",
                color = "blue", xlab = "Año", 
                ylab = "lambda = -1/2") + rotate_x_text(45)

g4 <- ggscatter(transformaciones, x = "Year", y = "lambda_cero",
                color = "blue", xlab = "Año", 
                ylab = "lambda = 0") + rotate_x_text(45)

g5 <- ggscatter(transformaciones, x = "Year", y = "lambda_un_medio",
                color = "blue", xlab = "Año", 
                ylab = "lambda = 1/2") + rotate_x_text(45)

g6 <- ggscatter(transformaciones, x = "Year", y = "lambda_dos",
                color = "blue", xlab = "Año", 
                ylab = "lambda = 2") + rotate_x_text(45)

# Crear una única figura con todos los gráficos de dispersión
dispersion <- ggarrange(g1, g2, g3, g4, g5, g6, ncol = 3, nrow = 2)
texto <- "Población transformada por año"
titulo <- text_grob(texto, face = "bold", size = 14)
dispersion <- annotate_figure(dispersion, top = titulo)
print(dispersion)

# Histogramas para la transformación de Tukey de la población y el año,
# usando distintos valores de lambda
h1 <- ggihistogram(transformaciones, bins = 10, x = "lambda_menos_dos", 
                   color = "blue", fill = "blue", 
                   xlab = "lambda = -2") + rotate_x_text(45)

h2 <- ggihistogram(transformaciones, bins = 10, x = "lambda_menos_uno", 
                   color = "blue", fill = "blue", 
                   xlab = "lambda = -1") + rotate_x_text(45)

h3 <- ggihistogram(transformaciones, bins = 10, x = "lambda_menos_un_medio", 
                   color = "blue", fill = "blue", 
                   xlab = "lambda = -1/2") + rotate_x_text(45)

h4 <- ggihistogram(transformaciones, bins = 10, x = "lambda_cero", 
                   color = "blue", fill = "blue", 
                   xlab = "lambda = 0") + rotate_x_text(45)

h5 <- ggihistogram(transformaciones, bins = 10, x = "lambda_un_medio", 
                   color = "blue", fill = "blue", 
                   xlab = "lambda = 1/2") + rotate_x_text(45)

h6 <- ggihistogram(transformaciones, bins = 10, x = "lambda_dos", 
                   color = "blue", fill = "blue", 
                   xlab = "lambda = 2") + rotate_x_text(45)

# Crear una única figura con todos los gráficos de histograma
histograma <- ggarrange(h1, h2, h3, h4, h5, h6, ncol = 3, nrow = 2)
texto <- "Histogramas de la población transformada"
titulo <- text_grob(texto, face = "bold", size = 14)
histograma <- annotate_figure(histograma, top = titulo)
print(histograma)

# Buscar la mejor transformación de Tukey usando una función de R
transformacion <- transformTukey(datos$Population, lambda = c(-4, 4, 0.001), 
                                 plotit = TRUE, useRanks = TRUE)
```

El valor óptimo de $\lambda$ es aquel que maximiza el estadístico entregado por la prueba de normalidad.

#### Transformaciones Box-Cox

Es una versión escalada de la transformación de Tukey, dada por:

$$
x'_{\lambda} = \frac{x^{\lambda} - 1}{\lambda}
$$

Se emplea la transformación logarítmica para $\lambda = 0$.

Para cualquier valor de $\lambda$, $x'_{\lambda} = 0$ cuando $x = 1$.

-   BoxCoxLambda(x, lower, upper): devuelve valor óptimo de $\lambda$ para el vector x.

-   BoxCox(x, lambda): devuelve un vector correspondiente a la transformación Box-Cox de x con parámetro lambda.

-   BoxCoxInv(x, lambda): revierte la transformación Box-Cox del vector x con parámetro lambda.

Donde:

-   x: vector numérico

-   lower: límite inferior para los posibles valores de $\lambda$

-   upper: límite superior para los posibles valores de $\lambda$

-   lambda: parámetro de la transformación

```{r}

```

### Pruebas para una o dos muestras

#### Prueba de suma de rangos de Wilcoxon

Alternativa no paramétrica a la prueba t de Student con muestras independientes.

Condiciones:

1.  Las observaciones de ambas muestras son independientes.
2.  La escala de medición empleada debe ser a lo menos ordinal, de modo que tenga sentido hablar de relaciones de orden ("igual que", "menor que", "mayor o igual que").

En un ejemplo de qué tan bueno puede ser algo del 1 al 7, ¿es lo mismo la diferencia entre 3 y 5, y entre 4 y 6? No, por lo que no se puede asumir que la escala es de intervalos iguales.

Ho: No hay diferencia en la usabilidad de ambas interfaces (se distribuyen de igual forma).

Ha: Sí hay diferencia en la usabilidad de ambas interfaces (distribuciones distintas).

Primer paso: Transformar todas las observaciones en un único conjunto de tamaño $n_T = n_A + n_B$ y ordenarlo de menor a mayor, a cada elemento asignándole un valor de rango de 1 a $n_T$, de acuerdo a la posición que ocupa en el conjunto ordenado. En caso de que un valor aparezca más de una vez, cada repetición toma como valor el rango promedio de todas las ocurrencias del valor.

La suma de rangos para la muestra combinada es:

$$
T_T = \frac{n_T (n_T + 1)}{2}
$$

Ventajas de trabajar con rangos

1.  El foco solo está en las relaciones de orden entre las observaciones, sin necesidad de que estas provengan de una escala de intervalos iguales.
2.  Esta transformación facilita conocer de manera sencilla algunas propiedades del conjunto de datos.

Media de rangos de la muestra combinada:

$$
\mu = \frac{n_T(n_T + 1)}{2} \frac{1}{n_T} = \frac{n_T + 1}{2}
$$

Si fuera cierta la Ho (en el dominio de los rangos) de que las medias de los rangos de las dos muestras son iguales, las observaciones en ambas muestras serían similares, por lo que se mezclarían de forma homogénea. Por lo tanto, se espera que los promedios de rangos para cada muestra se aproximen al rango promedio de la muestra combinada.

$$
\mu_A = n_A \frac{n_T+1}{2}
$$

$$
\mu_B = n_B \frac{n_T + 1}{2}
$$

#### Prueba de suma de rangos de Wilcoxon para muestras grandes

Asumiendo que Ho es verdadera, se puede demostrar que las distribuciones muestrales tienen la misma desviación estándar

$$
\sigma_T = \sqrt{\frac{n_An_B(n_T+1)}{12}}
$$

Cuando ambas muestras tienen tamaño mayor o igual a 5 se puede demostrar que provienen de una distribución normal.

$$
z = \frac{T_{obs} - \mu_{obs} \pm 0.5}{\sigma_T}
$$

-   $T_{obs}$ es cualquiera de los valores observados.

-   $\mu_{obs}$ es la media de la distribución muestral de $T_{obs}$

-   $\sigma_T$ es la desviación estándar de la distribución muestral de $T_{obs}$

Se debe emplear el siguiente factor de corrección de continuidad:

-   -0.5 si $T_{obs}$ \> $\mu_{obs}$

-   0.5 si $T_{obs}$ \< $\mu_{obs}$

Si se tiene como Ha que la interfaz A es mejor que la B, entonces se espera que las observaciones de mayor rango estén en A, por lo que $z_A$ sería positivo.

Solo permite calcular el valor p asociado a una hipótesis alternativa unilateral.

#### Prueba de suma de rangos de Wilcoxon para muestras pequeñas

No se puede usar el supuesto de normalidad.

Se puede calcular el máximo valor posible para la suma de rangos de cada muestra.

$$
T_{x[max]} = n_xn_y+\frac{n_x(n_x+1)}{2}
$$

$$
U_x = T_{x[max]} - T_x
$$

Siendo el valor estadístico el menor de ambos.

$$
U_A + U_B = n_An_B
$$

Si la hipótesis nula es verdadera:

$$
U_A = U_B = \frac{n_An_B}{2}
$$

Si la Ho es verdadera, ¿qué tan probable es obtener un valor de U al menos tan pequeño como el observado?

#### Prueba de suma de rangos de Wilcoxon en R

wilcox.test(x, y, paired = FALSE, alternative, mu, conf.level)

```{r}
#Ingresar los datos
a <- c(2.7, 6.6, 1.6, 5.1, 3.7, 6.1, 5.0, 1.4, 1.8, 1.5, 3.0, 5.3)
b <- c(5.0, 1.4, 5.6, 4.6, 6.7, 2.7, 1.3, 6.3, 3.7, 1.3, 6.8)

#Establecer nivel de significación
alfa <- 0.05

#Hacer prueba
prueba <- wilcox.test(a, b, alternative = "two.sided", conf.level = 1-alfa)
print(prueba)
```

Se prueba la distribución nula que la distribución de origen es dimétrica en torno al valor mu. Mu es el valor nulo para la mediana de la distribución de origen.

#### Prueba de rangos con signo de Wilcoxon

Condiciones

1.  Los pares de observaciones son independientes.
2.  La escala de medición empleada para las observaciones es intrínsicamente continua.
3.  La escala de medición empleada para ambas muestras debe ser a lo menos ordinal.

Ho: Las mismas personas no perciben diferencia en la usabilidad de ambas interfaces.

Ha: Las mismas personas consideran que la interfaz A tiene mejor usabilidad que la interfaz B.

Se calculan las diferencias entre cada par de observaciones y se descartan aquellas que sean 0. Se ordenan de menor a mayor y se les asigna rango con su signo.

Se procede a calcular W, siendo la suma de los rangos con signo.

Una muestra de tamaño n genera n rangos no empatados sin signo. Cada rango puede tomar valores positivos o negativos, por lo que para W se tienen $2^n$ combinaciones para signos y rangos.

Si Ho fuese cierta, los rangos positivos y negativos se distribuirían de manera homogénea, por lo que se espera que W sea cercano a 0.

Mientras mayor sea el n, más se acerca a una distribución normal.

$$
\sigma_W = \sqrt{\frac{n(n+1)(2n+1)}{6}}
$$

$$
z = \frac{W - 0.5}{\sigma_W}
$$

El supuesto de normalidad es válido solo para n \> 10.

wilcox.test(x, y, paired = TRUE, alternative, conf.level)

```{r}
#Ingresar los datos
a <- c(2.7, 6.6, 1.6, 5.1, 3.7, 6.1, 5.0, 1.4, 1.8, 1.5, 3.0, 5.3)
b <- c(5.0, 1.4, 5.6, 4.6, 6.7, 2.7, 1.3, 6.3, 3.7, 1.3, 6.8)

#Establecer nivel de significación
alfa <- 0.05

#Hacer prueba
prueba <- wilcox.test(a, b, alternative = "greater", paired = TRUE, conf.level = 1-alfa)
print(prueba)
```
